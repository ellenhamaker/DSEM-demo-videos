---
title: "Social Behaviour Dynamics: Week 2"
author: "Ellen Hamaker"
date: "ADS, 2021-2022"
mainfont: Arial
fontsize: 12pt
urlcolor: blue
output:
  html_document:
    highlight: default
    theme: paper
    toc: yes
    toc_float: yes
  pdf_document:
    latex_engine: xelatex
    toc: yes
    toc_depth: '5'
params:
  rcode: true
  answers: true
  answers2: false
---
# 1. Readings and podcast

Schafer, J. L., and Kang, J. (2008). Average causal effects from nonrandomized studies: A practical guide and simulated example. _Psychological methods, 13_, 279-313. DOI: 10.1037/a0014268

Reading questions to S&K:

1) How does the notation used in this paper relate to the notation used in the slides?

2) What would be an example from your field, where an average effect of the treated (ACE1) is of interest?

3) Unconfoundedness can be expressed as: $Y_{i}^0, Y_{i}^1 \perp \!\!\! \perp X_i$, and conditional unconfoundedness can be expressed as: $Y_{i}^0, Y_{i}^1 \perp \!\!\! \perp X_i | Z_i$. What does this mean, and how is it different from saying that $Y_i$ is independent of $X_i$?

4) What should be considered the preferred methods for estimating the ACE according to the results obtained by Schafer and Kang?

__HIGHLY RECOMMENDED__: Podcast episode from Serious Epi: https://seriousepi.blubrry.net/2021/10/28/s2e3-more-on-causal-inference-and-scientific-reasoning/



$~$

# 2. R exercises
In this exercises, we follow the analyses discussed in the paper by Schafer and Kang (2008), which have also been discussed in this week's lecture. There are nine techniques they cover; below, all of them will be included, but note that some of them are optional (they are included for the sake of completeness, but you do not have to study and understand them in detail).

We will also use the data from Schafer and Kang, which are in the data file called SchaferKangData.dat. These are simulated data, and hence the authors (and we) know what the correct answer to the question ``What is the effect of dieting on emotional distress?'' actually is. Hence, the purpose of the exercises here is to obtain a deeper understanding and hands-on experience with the diverse techniques. 

Make sure to compare the results you get throughout the exercises to those reported in Table 6 in Schafer and Kang. For null hypothesis tests, you can use a significance level of 0.05 throughout.

## 2.0 Data and R-packages
In this practical you will make use of various R-packages. If you haven't already, install the following packages:

```{r blokje0, echo=T, eval=T, message=F}
# install.packages("tableone")
# install.packages("MatchIt")
# install.packages("survey")
```

Load the data, which are in the datafile called SchaferKangData.dat. Take a look at the data set. See Table 3 in Schafer and Kang for a description of the variables. 

```{r blokje, echo=T, eval=T, message=F, include=params$rcode}
df <- read.table("SchaferKangData.dat", header=T)
df[1:10,]
```

$~$

## 2.1 Ignoring covariates 
When a randomized controlled trial (RCT) has been conducted, the treatment groups should not differ on any (pre-treatment)  covariate due to random assignment. In that case, the ACE can be computed by taking the difference in means between the two groups for the outcome variable. This is also referred to as the _prima facie effect_.  

### Method 1: _Compare means_

Although the current data are not generated by a RCT scenario, we will nevertheless consider this naive estimation approach for the causal effect.

$\blacktriangleright$ Compare the means between the groups on the outcome variable (see Equation (5) in S&K; use for instance `t.test()` in R).

```{r blokje3, echo=T, eval=T, message=F, include=params$rcode}
t.test1 <- t.test(DISTR.2 ~ DIET, df)
# Difference in means between the groups:
m1 <- t.test1$estimate[2]
m0 <- t.test1$estimate[1]
m1 - m0 #Note: the result of this command may carry on the header "mean for group 1", but it really is the difference in means.

# Standard error
t.test1$stderr
# p-value
t.test1$p.value

```

```{r blokje3_1, echo=T, eval=T, message=F, include=params$answers}
# The mean difference is the "prima facie" estimate of the average causal effect of dieting on distress. The results indicate that the average of the girls who did diet is (0.703-0.645=)0.059 higher than the average of the girls who did not diet ($SE=0.015$). This difference is statistically significant. 

```

### Investigating covariates

The mean difference above is based on the assumption that there is no confounding. However, we have a set of observed covariates, and if our data mimic a RCT, there should be no mean differences between the two groups on these covariates. We check this with the _standardized mean difference_ (rather than a t-test, because we do not want it to be dependent on sample size), that is: 

$$\Delta Z = \frac{(\bar{Z}|X=1) -(\bar{Z}|X=0)} {\sqrt{((S^2|X=1) + (S^2|X=0))/2}}$$

where 

* $\bar{Z}|X=x$ is the mean on covariate $Z$ in group $x$

* $S^2|X=x$ is the variance in group $x$

* $X=1$ is the diet group; $X=0$ is the non-diet group

$\blacktriangleright$ Determine the normalized difference between the girls who did diet versus the girls who did not diet on the first covariate, that is: DISTR.1 (emotional distress at wave 1). 

```{r blokje4, echo=T, eval=T, include=params$rcode, message=F}
df1 <- df[ which(df$DIET == 1), ]
df0 <- df[ which(df$DIET == 0), ]

(mean(df1$DISTR.1) - mean(df0$DISTR.1))/(sqrt( (var(df1$DISTR.1)+var(df0$DISTR.1))/2 )) 
```

$\blacktriangleright$ Instead of computing these standardized mean differences ourselves, we can also use the function `CreateTableOne()` from the package `tableone`. Run the code below.

```{r blokje4a, echo=T, eval=T, message=F}
library(tableone)
table1 <- CreateTableOne(vars=c("DISTR.1","BLACK", "NBHISP", "GRADE",
                      "SLFHLTH", "SLFWGHT", "WORKHARD", "GOODQUAL", 
		                  "PHYSFIT", "PROUD", "LIKESLF", "ACCEPTED", 
                      "FEELLOVD"), strata="DIET", data=df, 
                        test=FALSE)
```

$\blacktriangleright$ Obtain the table with standardize mean differences using `print(table1, smd=TRUE)`, and comment on the results

```{r blokje4b, echo=T, eval=T, message=F, include=params$answers}
print(table1, smd=TRUE)
# Most of the standardized mean differences (the last column) are
# larger than the rule of thumb of 0.1; this implies that there is
# considerable imbalance across the two groups with respect to these
# covariates. This means the data do not mimic an RCT very well.

# Hence, some action to tackle this is required.
```

$~$

## 2.2 Model the relation of $Z$ with $Y$
Schafer and Kang describe three techniques that are based on including possible confounders as covariates (or predictors) in the model:

* _ANCOVA_ (no interactions between predictors) and _regression_ (interactions between predictors)

* _regression estimation_, which is based on estimating the potential outcomes $Y_i^0$ and $Y_i^1$ for each participant based on the covariates

We will include all the covariates in our analyses below, even when they have a small standardized mean difference. In the latter case there may not be a need to correct for differences in them between the groups, but they may still account for variance in the outcome variable, and by accounting for this, we increase the power of our analysis. 

### Method 2: _ANCOVA/regression_
To run an ANCOVA, we can simply run a regression model _without interactions_ between the predictors (see Equation (6) in S&K). Our model here can be written as:

$$DISTR.2_{i} = \alpha + \theta DIET_i + \beta_1 DISTR.1_i + \beta_2 BLACK_i + \beta_3 NBHISP_i$$

$$ + \beta_4 GRADE_i+ \beta_5 SLFHLTH_i + \beta_6 SLFWGHT_i + \beta_7 WORKSHARD_i$$
$$ + \beta_8 GOODQUAL_i + \beta_9 PHYSFIT_i + \beta_{10} PROUD_i$$
$$ + \beta_{11} LIKESLF_i + \beta_{12} ACCEPTED_i + \beta_{13}FEELLOVED_i + e_i  $$

Note: Since the categorical variables DIET, BLACK and NBHISP are dummy variables, you do not need to treat them differently than the continuous covariates. If they would have three categories or more, you could include them as factor when using the function `glm`; alternatvily, you could create dummy variables for the various categories, and include this set of dummies as predictors in the regression model (like we did in the R exercises in Week 1).

$\blacktriangleright$ Run the ANCOVA model (for instance using the function `glm()` in R), and interpret the results.

```{r blokje6, echo=T, eval=T, message=F, include=params$rcode}
M2 <- glm(DISTR.2 ~ DIET	+ DISTR.1 + BLACK + NBHISP 
    + GRADE + SLFHLTH + SLFWGHT + WORKHARD + GOODQUAL 
		+ PHYSFIT + PROUD + LIKESLF + ACCEPTED + FEELLOVD,
		data=df)
summary(M2)

```

```{r blokje6_1, echo=T, eval=T, message=F, include=params$answers}
# The results indicate that after correcting for the effect of the covariates, the 
# effect of the treatment (i.e., DIET) on the outcome (i.e. DISTR.2) is not
# significant; the parameter estimate of the ACE is -0.014 ($SE=0.013$).
```

We can extend the ANCOVA model above by incorporating product terms between the predictors:

* product between covariate and itself: _quadratic effect_

* product between two covariates: _interaction_

* product between treatment and covariates: _non-parallel planes_ (see Figure 2 in Schafer and Kang) 

We will not proceed with this here (note Schafer and Kang consider the latter option in their paper), but two additional comments are in place:

* Adding such product terms quickly increases the number of parameters that we need to estimate; this reduces the power (especially relevant when dealing with small sample sizes).

* Before including interactions, one needs to center the covariates, and the interaction terms then needs to be centered again; failing to do so implies the main effect for treatment may not represent the average causal effect of treatment.

```{r blokje7, echo=T, eval=T, message=F, include=params$answers2}
# For those who are interested, this is how to run the 
# ANCOVA model with interaction between the treatment (DIET)
# and the covariates, thus allowing for non-parallel
# regression planes, as discussed in S&K.
# First, center the covariates at overall means
dfc <- df
dfc$DISTR.1 <- dfc$DISTR.1 - mean(dfc$DISTR.1)
dfc$BLACK <- dfc$BLACK - mean(dfc$BLACK)
dfc$NBHISP <- dfc$NBHISP - mean(dfc$NBHISP)
dfc$GRADE <- dfc$GRADE - mean(dfc$GRADE)
dfc$SLFHLTH <- dfc$SLFHLTH - mean(dfc$SLFHLTH)
dfc$SLFWGHT <- dfc$SLFWGHT - mean(dfc$SLFWGHT)
dfc$WORKHARD <- dfc$WORKHARD - mean(dfc$WORKHARD)
dfc$GOODQUAL <- dfc$GOODQUAL - mean(dfc$GOODQUAL)
dfc$PHYSFIT <- dfc$PHYSFIT - mean(dfc$PHYSFIT)
dfc$PROUD <- dfc$PROUD - mean(dfc$PROUD)
dfc$LIKESLF <- dfc$LIKESLF - mean(dfc$LIKESLF)
dfc$ACCEPTED <- dfc$ACCEPTED - mean(dfc$ACCEPTED)
dfc$FEELLOVD <- dfc$FEELLOVD - mean(dfc$FEELLOVD)

# Next, run the model with the interactions between
# DIET and each of the centered covariates
M2b <- glm(DISTR.2 ~ DIET + DISTR.1 + BLACK + NBHISP 
    + GRADE + SLFHLTH + SLFWGHT + WORKHARD + GOODQUAL 
		+ PHYSFIT + PROUD + LIKESLF + ACCEPTED + FEELLOVD
		+ DIET*DISTR.1 
		+ DIET*BLACK 
		+ DIET*NBHISP 
    + DIET*GRADE 
		+ DIET*SLFHLTH 
		+ DIET*SLFWGHT 
		+ DIET*WORKHARD 
		+ DIET*GOODQUAL 
		+ DIET*PHYSFIT 
		+ DIET*PROUD 
		+ DIET*LIKESLF 
		+ DIET*ACCEPTED 
		+ DIET*FEELLOVD,
		data=dfc)
summary(M2b)
# This shows the ACE is estimated to be -0.006 ($SE=0.015$),
```

### Method 3: _Regression estimation_

Regression estimation is _not_ the same as regression analysis (which was discussed above). In regression estimation, we make actual _predictions of the potential outcomes that were not observed_, and use these to compute the causal effect of interest. 

To use regression estimation (see Equation (15) in S&K), you have to:

* divide the data set into those who were treated and those who were not treated

* estimate a regression model (with all the covariates) in each group separately

* obtain the parameter estimates from each group (see Equations (13) and (14) in S&K)

* use these and the covariates to predict the potential outcomes $\hat{Y}_i^0$ and $\hat{Y}_i^1$ 

* compute the average difference between these _predicted_ potential outcomes

Hence, this approach is a technique to impute the missing values in the data file that only contains the potential outcomes that were observed. 

(Note that it is not easy to obtain the right $p$-value for this mean difference: While you could run a paired t-test, this does not take into account that the potential outcomes are actually estimated rather than observed; we will ignore this here.) 

As this is a somewhat more challenging approach, some of the code will be presented immediately, so that you can work from there to answer the questions.

We start with creating separate data sets for the two treatment groups, and running a regression analysis for each group separately: 

```{r blokje8, echo=T, eval=T, message=F, include=T}
df1 <- subset(df, DIET==1)
df0 <- subset(df, DIET==0)

# Regression analysis with only people with X=1:
M3.1 <- glm(DISTR.2 ~ + DISTR.1 + as.factor(BLACK) + as.factor(NBHISP) 
           	+ GRADE + SLFHLTH + SLFWGHT + WORKHARD + GOODQUAL 
		        + PHYSFIT + PROUD + LIKESLF + ACCEPTED + FEELLOVD,
		        data=df1)

# Regression analysis with only people with X=0:
M3.0 <- glm(DISTR.2 ~ + DISTR.1 + as.factor(BLACK) + as.factor(NBHISP) 
           	+ GRADE + SLFHLTH + SLFWGHT + WORKHARD + GOODQUAL 
	          + PHYSFIT + PROUD + LIKESLF + ACCEPTED + FEELLOVD,
		        data=df0)
```

Now we can obtain estimates for everyone (whether we observed $X=1$ or $X=0$) for the potential outcome under treatment (i.e., $\hat{Y}^1_i$) and under no treatment (i.e., $\hat{Y}^1_i$):

```{r blokje8aaa, echo=T, eval=T, message=F, include=T}
# Obtain a prediction for the outcome using all the cases, based on 
# the parameter estimates obtained above and saved in M3.1:
M3.est.Y1 <- predict(M3.1, newdata = df)

# Do the same, but now with the parameters saved in M3.0:
M3.est.Y0 <- predict(M3.0, newdata = df)
```


```{r blokje8a, echo=T, eval=T, message=F, include=params$answers2}
# How to do it yourself:
# Obtain the parameters from X=0 group
M3.b0 <- as.matrix(M3.0$coeff)
M3.b0

# Obtain the paramaters from X=1 group
M3.b1 <- as.matrix(M3.1$coeff)
M3.b1

# Create a matrix that contains: 
# a) a column with 1's for all individuals (for the intercept)
# b) the observed covariates
Z <- as.matrix(cbind(rep(1,nrow(df)),df[,1:13]))

# Multiple the matrix that contains the observed covariates with
# the vector with parameter estimates for the non-diet group and 
# also for the diat group: This gives us the predicted potential
# outcomes for every person when X=0 and when X=1.

M3.est.Y0 <- Z%*%M3.b0
M3.est.Y1 <- Z%*%M3.b1 

```


$\blacktriangleright$ How can the results be used to estimate the average causal effect? 

```{r blokje8aa, echo=T, eval=T, message=F, include=params$rcode}
# Look at the predicted potential outcomes
cbind(M3.est.Y0, M3.est.Y1)[1:10,]

# Estimate the causal effect now, using a t-test
t.test(M3.est.Y0, M3.est.Y1, paired = TRUE, alternative = "two.sided")
```

```{r blokje8ab, echo=T, eval=T, message=F, include=params$answers}
# Although in reality we can only ever observe one potential outcome
# per person, with this technique we obtained an estimate for each
# person's potential outcome under treatment (X=1) and under no
# treatment (X=0). We can now use these estimated potential outcomes
# to compute the ACE by taking the mean difference.

# It is important to realize the p-value that is obtained (and the 
# standard error) are not correct; they are based on the assumption
# these are observed, rather than estimated scores.
```



$\blacktriangleright$ __(OPTIONAL)__ Above we have used the predicted potential outcomes for everyone. However, one of them is actually observed, and we could use that one instead of the predicted potential outcome (i.e., we use the observed fact, and predict only the counterfact). Hence, for individuals in the no treatment condition you use $Y_i$ instead of $\hat{Y}_i^0$, and for those in the treatment condition you use $Y_i$ instead of $\hat{Y}_i^1$ (this is also described around Equation (16) in S&K). Check whether this leads to a different result.

```{r blokje8b, echo=T, eval=T, message=F, include=params$rcode}
# Take the predicted potential outcome for X=0
# and only for those for whom we observed X=0
# do we overwrite the predicted potential outcome
M3b.Y0 <- M3.est.Y0
M3b.Y0[df$DIET==0] <- df$DISTR.2[df$DIET==0]

# Do the same for the predicted potential outcome for X=1
M3b.Y1 <- M3.est.Y1
M3b.Y1[df$DIET==1] <- df$DISTR.2[df$DIET==1]

# Now do the t-test with these (observed and predicted) potential outcomes:
t.test(M3b.Y0, M3b.Y1, paired = TRUE, alternative = "two.sided")
```

```{r blokje8bb, echo=T, eval=T, message=F, include=params$answers}
# Although the predicted potential outcomes and the actual observed
# potential outcomes are not exactly the same, using only the predicted
# potential outcomes (like we did first), or using a combination of 
# predicated and observed potential outcomes (as we did here), makes
# virtually no difference for the estimated causal effect.

# REMEMBER: We cannot use the p-value of the t-test here to say anything
# about the significance, as the variables we use here are not (entirely)
# observed, and we would need to adjust for additional uncertainty.
```

### Conclusion 
In both Method 2 and 3 we have assumed linear relations between the covariates $Z_i$ and the outcome $Y_i$. This can be a problematic assumption when the predictions that we need to make require substantial extrapolation away from the sample mean in one of the treatment groups. 

$\blacktriangleright$ To determine whether it is likely to be a problem, we can use the _standardized mean differences_ again (see above and in the lecture slides). What is the rule of thumb for this, and what is your conclusion? 

```{r blokje8c, echo=T, eval=T, message=F, include=params$answers}
# As before:
print(table1, smd=TRUE)

# The rule of thumb for this is that (absolute) values larger than 0.3 indicate 
# that there is substantial extrapolation needed, which may lead to bias. 

# Large standardize mean differences imply that the linear approximation may be
# problematic, as one has to make predictions for the treated using the
# parameters of the untreated far away from the mean of 
# the covariates of the untreated, and vice versa (i.e., extrapolation).

# Here several covariates have (absolute) SMDs larger than 0.3, which implies
# linear extrapolation could be a problem. Hence, it may be more appropriate to
# use a techniques based on the propensity score (which all methods below do).
```

$~$

## 2.3 Model the relation of $Z$ with $X$
Above, we included the covariates as predictors of the outcome. These approaches can be quite unstable, when we consider diverse combinations of predictors. Also, there may be problems with the linear extrapolation (when the standardized mean differences are larger than 0.30).

There are various alternative techniques that are all based on using the _propensity scores_: This is an individual's probability of treatment based on their scores on the covariates (i.e., $P(X=1|Z=Z_i)$. If we know how likely a person was to receive treatment, we can use this information to mimic a randomized controlled trial (in which everyone has the same probability of receiving treatment). Schafer and Kang consider three common techniques for this:

* _matching_, in which we try to create pairs of a treated and an untreated individual that have the same propensity score

* _inverse probability weighting_, in which we create a pseudo-population that is balanced on the covariates 

* _subclassification or stratification_, in which we create strata in which there are no (meaningful) differences in the covariates left

### Estimate the propensity score
We will start with estimating a propensity score for each person in the data set. This score will then be used in the diverse techniques that follow. 

$\blacktriangleright$ To compute a propensity score, run a logistic regression model in which the treatment variable X (which has values 0 and 1) is the outcome variable, and the covariates are the predictors. Make sure to save the probability for each person for scoring 1 on $X$ (here: DIET). You can use the `glm` function from the `stats` package for this.

```{r blokje9, echo=T, eval=T, message=F, include=params$rcode}
# Run the logistic regression analysis
logreg <- glm(DIET ~ DISTR.1 + as.factor(BLACK) + as.factor(NBHISP) 
                    + GRADE + SLFHLTH + SLFWGHT + WORKHARD + GOODQUAL 
		                + PHYSFIT + PROUD + LIKESLF + ACCEPTED + FEELLOVD, 
           	        family = binomial(), data = df)

# Obtain a prediction of the probability of treatment (i.e., DIET=1) 
ps <- predict(logreg, type = "response")

# Add this predicted probability to the datafile
df$ps <- ps

# Look at the datafile 
round(df[1:10,], 2)

# The last column in the datafile now contains the predicted 
# probability of being treated, based on the covariates.
```

Now that we have the propensity scores, we should first consider the distribution of propensity scores in each of the treament groups separately, to determine whether there is overlap between the propensity scores of the two groups. 

$\blacktriangleright$ Make a histogram to look at this, discuss what you see, and why this is important.

```{r blokje10, echo=T, eval=T, message=F, include=params$rcode}
# Create separate data files (which now include the propensity scores)
# for those treated and those not treated:
df1 <- df[ which(df$DIET == 1), ]
df0 <- df[ which(df$DIET == 0), ]

# Create histograms, then plot one and add the other: 
hist0 <- hist(df0$ps, breaks=30, plot=FALSE)
hist1 <- hist(df1$ps, breaks=30, plot=FALSE)
plot( hist0, col=rgb(0,0,1,1/4), xlim=c(0,1), 
	    xlab="Propensity score", 
      main="Histogram of propensity scores")  
plot( hist1, col=rgb(1,0,0,1/4), xlim=c(0,1), add=T) 

```


```{r blokje10_1, echo=T, eval=T, message=F, include=params$answers}
# What we see is that the distributions of propensity scores of the
# two groups seem to overlap well, even in the tails. 
# If this would not be the case, that would be an indication that the 
# assumption of positivity is violated.
# That is, at each possible combination of the covariates, which is
# now summarized with the propensity score, there should be both
# treated and non-treated individuals in our sample.
```

Now that we have determined the propensity scores and their distributions for the the treated and the non-treated overlap well, we can make use of these scores within different techniques.

### Method 4: _Matching_
Matching based on the propensity scores is the first technique in this category that we consider. It is based on finding people in the both treatment groups that have similar propensity scores: The idea is that these individuals are comparable on the entire set of covariates, and can thus be considered randomly assigned to the two condition. 

In practice, this is done by taking a person from the smallest of the two groups (here the group for which DIET=1), and finding a person in the other group that is most like this person in terms of their propensity score. We can do this using the function `matchit()` from the package `MatchIt` in R. Please note that this will give us slightly different results than those obtained by S&K.

To run the matching function, we plug in the same expression as we used above to obtain the porpensity scores, and use the method "nearest":  

```{r blokje11, echo=T, eval=T, message=F, include=T}
library(MatchIt)
matchdat <- matchit(DIET ~ DISTR.1 + as.factor(BLACK) + as.factor(NBHISP) 
    		+ GRADE + SLFHLTH + SLFWGHT + WORKHARD + GOODQUAL 
		    + PHYSFIT + PROUD + LIKESLF + ACCEPTED + FEELLOVD, 
        method = "nearest",  data = df)

```

$\blacktriangleright$ Describe the information that is included in the output (matchdat). 

```{r blokje11_1, echo=T, eval=T, message=F, include=params$answers}
matchdat
# The results indicate that the original sample consisted of 
# 6000 individuals, and that the matched sample consists of 
# 2440 individuals. This is because the number of treated individuals
# is 1220, and these were all matched with a non-treated person. 

# Note that a different model for the propensity scores (e.g., including 
# interaction terms between two covariates, or non-linear relations by 
# squaring covariates), would lead to different propensity scores, and
# these may subsequently lead to different matches. Hence, it is really
# model dependent!
```

$\blacktriangleright$ There are two useful plotting options regarding the propensity scores of our matched pairs: `plot(matchdat,type="jitter")` and `plot(matchdat,type="hist")`. Get both plots, and describe what they represent. 

```{r blokje11a, echo=T, eval=T, message=F, include=params$rcode}
plot(matchdat,type="jitter")
```
```{r blokje11a_1, echo=T, eval=T, message=F, include=params$answers}
# This is a plot of the propensity scores of four different subgroups
# from our original data file:
# 1) Those from the treatment group for whom there was no match
# 2) Those from the treatment group for whom there was a match
# 3) Those from the control group for whom there was a match
# 4) Those from the control group for whom there was no match
# It shows the first group is empty; it shows the last group
# has relatively low propensity scores; the middle two groups
# seem pretty similar in terms of their propensity score
# distribution (as expected, as these are the matched cases).
```

```{r blokje11a_2, echo=T, eval=T, message=F, include=params$rcode}
plot(matchdat,type="hist")
```

```{r blokje11a_3, echo=T, eval=T, message=F, include=params$answers}
# This plot shows the histograms of the propensity scores
# of the two treatment groups in the original dataset on the left
# and for the matched groups on the right; it shows that the latter
# are far more similar than the former (as one would expect).
```

$\blacktriangleright$ To do the analysis on the matched cases only, we need to create a new data file with only the matched cases, using: `df.match <- match.data(matchdat)`. Create the Table 1 for this matched data set. What can you conclude?

```{r blokje11b, echo=T, eval=T, message=F, include=params$rcode}
# To extract the new datafile from the original one:
df.match <- match.data(matchdat)

# Create Table 1:
table1 <- CreateTableOne(vars=c("DISTR.1","BLACK", "NBHISP", "GRADE",
                      "SLFHLTH", "SLFWGHT", "WORKHARD", "GOODQUAL", 
		                  "PHYSFIT", "PROUD", "LIKESLF", "ACCEPTED", 
                      "FEELLOVD"), strata="DIET", data=df.match, 
                        test=FALSE)
print(table1, smd=TRUE)
```

```{r blokje11c_1, echo=T, eval=T, message=F, include=params$answers}
# Note that the two groups now each have 1220 cases (compared to 4789 and
# 1220 respectively before). This is because we are now working with only
# matched cases, and there was a match in the non-treated group for every
# treated person.

# The table shows that the standardized mean differences are all 
# quite small in this matched data set; this means the two groups
# are now very similar on the covariates, just as one would 
# expect in an RCT. This is good news!

# Hence, matching seems to mimic an RCT here (at least with respect 
# to observed covariates; note there may still be unobserved confounding).
```

$\blacktriangleright$ Subsequently, investigate with a t-test whether the means on the outcome variable DISTR.2 differ among the matched cases. 

```{r blokje12a, echo=T, eval=T, message=F, include=params$rcode}
# Do a t-test on the matched data file:
t.test2 <- t.test(DISTR.2 ~ DIET, df.match)
t.test2

# Note the means per group are included at the bottom.
# We can also compute the mean difference, using:
t.test2$estimate[2] - t.test2$estimate[1]
```

```{r blokje12, echo=T, eval=T, message=F, include=params$answers}
# The ACE is now estimated to be: -0.0222
# It is not significantly different from zero, according to the t-test.
```


$\blacktriangleright$ Compare this result to the mean comparison you did at the start; explain why the mean differences that you have just determined is an estimate of the ACE1 rather than of the ACE.
```{r blokje13, echo=T, eval=T, message=F, include=params$answers}
# Initially, the difference was 0.0596, meaning that those who diet (X=1)
# experience MORE distress than those who do not diet (X=0).

# Here the mean difference between the matched cases is 0.703-0.725=-0.022,
# meaning that the distress for those who did diet (X=1) is actually
# LOWER than that of those who did not diet (X=0).

# Note that the matched cases are based on all the girls in our initial sample
# with X=1; hence, we now have the ACE for the treated. This implies that among 
# all those girls who are LIKELY to diet (X=1), actually dieting (X=1) seems 
# to result in LESS distress than not dieting (X=0).

# However, the difference is not a significant difference.
```

### Method 5: _IPW_
We can also use inverse probability weighting (IPW). In this case, the estimated propensity scores $\hat{\pi}_i$ is used to determine the probability that an individual would have received the treatment that they received: 

* for the treated ($X_i=1$) this is simply $\hat{\pi}_i$

* for the non-treated ($X_i=0$) this is $1-\hat{\pi}_i$. 

Next, we can use these probabilities as weights, by taking their inverse: That way, a case that received a treatment that she was very likely to receive, will get a small weight, while a case that received a treatment that she was very unlikely to receive, will get a large weight. Thus, the inverse probability weight indicates the number of persons from the population that this person represents. For the treated, this weight is $1/\hat{\pi}_i$; for the untreated, it is $1/(1-\hat{\pi}_i)$. 

$\blacktriangleright$ Compute the ACE using this IPW (see Equation (20) in S&K).

```{r blokje14, echo=T, eval=T, message=F, include=params$rcode}
Y <- df$DISTR.2
X <- df$DIET
mu1hat <- sum( X*Y/ps ) / sum(X/ps)
mu0hat <- sum( (1-X)*Y/(1-ps) ) / sum((1-X)/(1-ps))
mu1hat - mu0hat

```
```{r blokje14_1, echo=T, eval=T, message=F, include=params$answers}
# The latter difference is the estimate of the ACE. 
# Obtaining a p-value for this, is tricky. In the appendix of S&K, ways of computing
# standard errors for the estimate are provided.

```
```{r blokje14_2, echo=T, eval=T, message=F, include=params$answers}
# For those who are interested, a more sophisticated
# way of getting the ACE using IPW is given below; it is based on
# using the package survey in R.
library(survey)
library(tableone)
weight<-ifelse(df$DIET==1,1/(df$ps),1/(1-df$ps))
weighteddata<-svydesign(ids = ~ 1, data =df, weights = ~ weight)
weightedtable <-svyCreateTableOne(vars=c("DISTR.1","BLACK", "NBHISP", "GRADE",
                      "SLFHLTH", "SLFWGHT", "WORKHARD", "GOODQUAL", 
		                  "PHYSFIT", "PROUD", "LIKESLF", "ACCEPTED", 
                      "FEELLOVD"), strata = "DIET", 
                      data = weighteddata, test = FALSE)
print(weightedtable, smd = TRUE)
# This shows that in the pseudo-population that was created
# using IPW, the two groups do not differ much any more on
# most of the covariates; however, there is one covariate 
# SLFWGHT, whose standardized mean difference exceeds the
# rule of thumb value of 0.1. This implies that IPW is not 
# entirely successful here in mimicing an RCT. 
# We nevertheless proceed, but it would be better to check
# whether there are for instance very large weights, such 
# that there are cases that have a disproportional effect
# on the results, and to fix this first (for instance by
# deleting these cases, or replacing their weight by a large
# yet not excessive value). Hopefully, that would fix the 
# problem with the standardized mean differences.
# For now we proceed, using a function from the package survey.
msm <- svyglm(DISTR.2 ~ DIET, design = weighteddata)
summary(msm)
confint(msm)
# This shows that the effect of dieting is now estimated to be
# -0.005 (SE=0.030), which is not significantly different 
# from zero. 
```

### Method 6: _Subclassificiation_
Subclassification, also known as stratification, is a method that consists of creating classes (strata) based on the propensity scores. The idea is that the individuals within each stratum are rather similar with repect to their propensity score, and thus with respect to the entire set of covariates on which the propensity score is based; if the covariates are well balanced within each stratum, this is a way to mimic an RCT within each stratum. By subsequently estimating the ACE in each stratum (using a mean comparison such as Method 1, or an ANCOVA or regression analysis such as Method 2), we can determine the causal effect for individuals who are similar with regard to the entire set of covariates (as these are used to determine the propensity scores). 

$\blacktriangleright$ Begin with creating five strata based on the propensity scores (for instance, use the function cut() in R); each stratum should contain 20% of the (total number of) observations.

```{r blokje15, echo=T, eval=T, message=F, include=params$rcode}
df$stratum <- cut(df$ps, 
                    breaks=c(quantile(df$ps, probs=seq(0,1,0.2))),
                    labels=seq(1:5),
                    include.lowest=TRUE)

# We can also make a plot of these quantiles; this is based on
# using the same histrogram we had before, now adding vertical 
# lines for where the breaks of the strat are.

plot( hist0, col=rgb(0,0,1,1/4), xlim=c(0,1), 
	xlab="Propensity score", main="Histogram of propensity scores \nwith quantile breaks")  
plot( hist1, col=rgb(1,0,0,1/4), xlim=c(0,1), add=T) 

br <- c(quantile(df$ps, probs=seq(0,1,0.2)))

abline(v=br[2],col="black",lwd=3)
abline(v=br[3],col="black",lwd=3)
abline(v=br[4],col="black",lwd=3)
abline(v=br[5],col="black",lwd=3)

# This shows that especially the fifth stratum is
# very wide (in the paper by Schafer and Kang they
# decide to further split the fourth stratum in two
# groups, and the fifth in four groups, because these
# are rather wide).

# We could also further investigate whether we need more strata
# by looking at the standardized mean differences in each stratum;
# these should be small, as the idea is that each stratum can be
# thought of as an RCT in which the assignment to treatment is
# random, and thus does not depend on any of the covariates.
```

$\blacktriangleright$ Next, compute the ACE in each stratum based on the mean difference. 

```{r blokje16, echo=T, eval=T, message=F, include=params$rcode}
# We perform a t-test in each stratum.

results <- matrix(,5,1)

for (quintiles in c(1:5)) {
  t.test3 <- t.test(DISTR.2 ~ DIET, data = df[which(df$stratum==quintiles),])
  print(t.test3)
  # Difference in means:
  results[quintiles,1] <- t.test3$estimate[2] - t.test3$estimate[1]
}

```
```{r blokje16_1, echo=T, eval=T, message=F, include=params$answers}
# This shows that the results differ per stratum; only in stratum 4 do we find a significant difference. 
```

$\blacktriangleright$ Subsequently, you can compute the overall ACE by taking the average of the stratum-specific ACE's (weighted by the stratum size). 

```{r blokje16b, echo=T, eval=T, message=F, include=params$answers}
# Note that since our five strata are based on quantiles, the sample
# size of each stratum will be the same (ie 1/5th of the total sample size)
# such that each stratum-specific ACE adds equally to the total. 
# Note that this also means that our ACE estimate will differ somewhat
# from the ACE estimate reported in Table 6 by Schafer and Kang, as they
# had further divided the fifth stratum.
# To get the ACE, we simply take the mean of the stratum-specific ACEs:
mean(results[,1])
# Note further that we do not have an SE for this estimate 
# (this is a bit more complicated to obtain).
```

### Conclusion
The three methods that we considered in this category are all based on using the propensity score, that is, the probability of being treated given the covariates. The goal of these techniques is to somehow mimic the situation we get in an RCT, where the probability of treatment is independent of the covariates. In matching, this is done by creating pairs of a treated and an untreated person who have (almost) identical propensity scores, resulting in a smaller but balanced dataset; in inverse probability weighting, this is done by weighing each person's observation by their inverse probability of received treatment, thereby creating a balanced peudo-population; and in subclassification this is done by creating strata based on the propensity scores such that within each stratum the covariates are balanced. In each approach, we should check whether it balances the covariates, for instance, by considering the standardized mean differences (for other options, see for instance: Austin, P. c. (2009). Balance diagnostics for comparing the distribution of baseline covariates between treatment groups in propensity-score matched samples. _Statistics in Medicine, 28_, 3093-3107.  https://doi.org/10.1002/sim.3697). 

$~$

## 2.4 Dual-modeling stategies
In the strategies above, we either accounted for the relation between covariates and the outcome, or between the covariates and the treatment. Schafer and Kang consider three approaches that do both:

* Weighted residual bias corrections, which combines Methods 3 and 5

* Weighted regression estimation, which also combines Methods 3 and 5

* Regression estimation with propensity-score covariates, which combines Methods 3 and 6

These techniques are also referred to as doubly-robust, as they perform well even when only the model that relates treatment to the covariates (i.e., the model for the propensity scores) is specified correctly, or the model that relates the outcome to the covariates is specified correctly.

### Method 7 (OPTIONAL): _Weighted residual bias corrections_
In this approach, we use the ACE we computed for Method 3 (based on mean differnce in the estimated potential outcomes), with a correction based on the estimated residuals. This requires us to estimate the residuals by subtracting the observed score $Y_i$ from the estimated potential outcome. These are then plugged into the second and third term of Equation (30) in S&K.

Note that the ACE estimate here will deviate a little from that reported in Table 6; this is probably due to one of the covariates being omitted there when they computed the propensity scores.

$\blacktriangleright$ Estimate this version of the ACE.

```{r blokje17, echo=T, eval=T, message=F, include=params$rcode}
# We make use of est.Y0 and est.Y1 (the estimated potential
# outcomes) from Method 3. We use these to estimate the residuals:
M7.est.E0 <- M3.est.Y0 - Y
M7.est.E1 <- M3.est.Y1 - Y

# Subsequently we compute the three terms of Equation 22 
# from Schafer and Kang, and then determine the ACE:
term1 <- mean( M3.est.Y1 - M3.est.Y0)
term2 <- sum( X*M7.est.E1/ps ) / sum(X/ps)
term3 <- sum( (1-X)*M7.est.E0/(1-ps) ) / sum((1-X)/(1-ps))
ACE <- term1 + term2 - term3
ACE 
```

Again, we do not have an SE for this estimate; this is a bit more complicated to obtain. 

### Method 8 (OPTIONAL): _Weighted regression estimation_
Weighted regression estimation is similar to the regression estimation (Method 3), which was based on estimating the regression coefficients for those that were treated and for those that were not treated, and using these regression coefficients to then make predictions of the potential outcomes for each person in each condition. The difference with Method 3 is that here we include the inverse probability weights (i.e., as in Method 5), when estimating the parameters.

$\blacktriangleright$ Note that when using the function `glm()`, you can just add weights to the function. Compute the ACE using this approach. Note that to get the right estimate of an SE is more complicated. 

```{r blokje18, echo=T, eval=T, message=F, include=params$rcode}
# For Method 3 we already created two separate datasets:
# df0 <- subset(df, DIET==0)
# df1 <- subset(df, DIET==1)

# Here we create the inverse probability 
# weights within each treatment level:
df0$wt0 <- 1/(1-df0$ps)
df1$wt1 <- 1/df1$ps

M8.0 <- glm(DISTR.2 ~ + DISTR.1 + as.factor(BLACK) + as.factor(NBHISP) 
           	+ GRADE + SLFHLTH + SLFWGHT + WORKHARD + GOODQUAL 
		+ PHYSFIT + PROUD + LIKESLF + ACCEPTED + FEELLOVD,
		weights=wt0, data=df0)
b0 <- M8.0$coeff

M8.1 <- glm(DISTR.2 ~ + DISTR.1 + as.factor(BLACK) + as.factor(NBHISP) 
           	+ GRADE + SLFHLTH + SLFWGHT + WORKHARD + GOODQUAL 
		+ PHYSFIT + PROUD + LIKESLF + ACCEPTED + FEELLOVD,
		weights=wt1, data=df1)
b1 <- M8.1$coeff

# We already created a matrix with the predictor variables for the 
# entire set (for Method 3), using:
# Z <- cbind(rep(1,nrow(df)),df[,1:13])

est.Y0 <- as.matrix(Z)%*%as.matrix(b0)
est.Y1 <- as.matrix(Z)%*%as.matrix(b1) 

t.test4 <- t.test(est.Y0, est.Y1, paired = TRUE, alternative = "two.sided")
t.test4$estimate
t.test4$stderr
```

### Method 9: _Regression estimation with propensity-score covariates_
Method 9 is based on including covariates based on the propensity score.This can be done in various ways; here we follow the dummy approach used by Schafer and Kang.   

$\blacktriangleright$ Create 10 dummy variables based on the propensity scores (similar to creating the strata in Method 6). 

```{r blokje20, echo=T, eval=T, message=F, include=params$rcode}

df$stratum9 <- cut(df$ps, 
                    breaks=c(quantile(df$ps, probs=seq(0,1,0.1))),
                    labels=seq(1:10),
                    include.lowest=TRUE)

df$D1 <- 1*(df$stratum9==1)
df$D2 <- 1*(df$stratum9==2)
df$D3 <- 1*(df$stratum9==3)
df$D4 <- 1*(df$stratum9==4)
df$D5 <- 1*(df$stratum9==5)
df$D6 <- 1*(df$stratum9==6)
df$D7 <- 1*(df$stratum9==7)
df$D8 <- 1*(df$stratum9==8)
df$D9 <- 1*(df$stratum9==9)
df$D10 <- 1*(df$stratum9==10)
```


$\blacktriangleright$ Use a similar approach as in Method 3, where you predict for everyone:

* the potential outcome for when treated (i.e., $\hat{Y}^1$), based on a model for those who were treated ($X=1$)

* the potential outcome for when not treated (i.e., $\hat{Y}^0$), based on a model for those who were not treated ($X=0$)

In the regression models use all the covariates that you used before, and add 9 of the dummies in the regression model which also includes the covariates as predictors, and determine the predicted values (i.e., the estimated potential outcomes). When a potential outcome was actually observed, replace the predicted score by the observed score. Then estimate the ACE by computing the average difference between the potential outcomes. Again, obtaining a correct estimate of the SE is more involved.

```{r blokje20a, echo=T, eval=T, message=F, include=params$rcode}
# Create separate data files for the treated and non-treated 
# (similar to Method 3):
df0.M9 <- subset(df, DIET==0)
df1.M9 <- subset(df, DIET==1)

# Run the regression model for those not treated (X=0)
M9.0 <- glm(DISTR.2 ~ + DISTR.1 + as.factor(BLACK) + as.factor(NBHISP) 
           	+ GRADE + SLFHLTH + SLFWGHT + WORKHARD + GOODQUAL 
		        + PHYSFIT + PROUD + LIKESLF + ACCEPTED + FEELLOVD
		        + D1 + D2 + D3 + D4 + D5 + D6 + D7 + D8 + D9,
		        data=df0.M9)

# Run the regression model for those treated (X=1)
M9.1 <- glm(DISTR.2 ~ + DISTR.1 + as.factor(BLACK) + as.factor(NBHISP) 
           	+ GRADE + SLFHLTH + SLFWGHT + WORKHARD + GOODQUAL 
		        + PHYSFIT + PROUD + LIKESLF + ACCEPTED + FEELLOVD
		        + D1 + D2 + D3 + D4 + D5 + D6 + D7 + D8 + D9,
		        data=df1.M9)

# Obtain predictions for both potential outcomes for every person
# based on the two models above
M9.est.Y0 <- predict(M9.0, newdata=df)
M9.est.Y1 <- predict(M9.1, newdata=df)

# OPTIONAL: 
# For those who received X=1, we can replace the predicted
# potential outcome with the observed score:
M9.Y0 <- M9.est.Y0
M9.Y0[df$DIET==0] <- df$DISTR.2[df$DIET==0]
# For those who received X=1, we can replace the predicted
# potential outcome with the observed score:
M9.Y1 <- M9.est.Y1
M9.Y1[df$DIET==01] <- df$DISTR.2[df$DIET==1]

```

$\blacktriangleright$ Estimate the ACE by computing the average difference between the potential outcomes that you (partly) estimated. (Note that again, obtaining a correct estimate of the SE is more involved, as the variables we are using are (partly) based on estimates.)

```{r blokje20b, echo=T, eval=T, message=F, include=params$rcode}
t.test5 <- t.test(M9.Y0, M9.Y1, paired = TRUE, alternative = "two.sided")
t.test5
```


```{r blokje20c, echo=T, eval=T, message=F, include=params$answers}
# The mean difference is 0.000897, which would be the ACE obtained with
# this method. It is positive, implying the average potential outcome
# under treatment is higher than the average potential outcome under
# no treatment. Put differently, it suggests that dieting leads to more
# distress. Note however that the difference is very small (and we cannot
# determine whether it is significant; that would require a different 
# computation of the p-value, as this test is not based on observed variables). 
```



## 2.5 Overall Conclusion
By now you probably see that the number of ways that we can account for covariate imbalance is about infinite. Ignoring the covariates (Method 1), is obviously not a good idea; hence, deciding which covariates to inlcude is a first important step, which we have not really discussed here (we will focus on this in more detail in week 3 and following weeks in the course). 

But even if we have decided which baseline covariates we need to account for, the options are almost limitless. In the ANCOVA and regression estimation procedures (Methods 2 and 3), we can add interactions and non-linear effects, for instance through using spline fitting. In all the other techniques that are based on propensity scores (Methods 4 to 9), we can also consider interactions and non-linear effects of covariates when predicting the log odds. Moreover, when using matching techniques (Method 4), we can choose to have more than one match per person, and we can choose between matching with or without replacement. In inverse probability weigthing (Method 5), we can decide to standardize the weights or not, and there are different ways to handle outliers. For subclssification (Method 6), we have to decide how many strata to create, and whether to further subdivide wide strata or not. The final category of techniques (Methods 7, 8, and 9) is based on combinations of the other techniques, and therefor allow for even more reserchers degrees of freedom. 

To make matters worse, different methods and different choices may lead to different results and even different (substantive) conclusions, as we have also seen here. Unfortunately, there is no one method that always performs best under all circumstances. Hence, it is advisable to apply multiple methods to see whether the results are robust, or that they contradict each other. Furthermore, to make informed decisions on what to do---and what to avoid---under particular circumstances, it can be very helpful to check out simulation studies, such as the one by Schafer and Kang, or the more recent study by Goetghebeur, le Cessie, Stavola, Moodie and Waernbaum (2020. Formulating causal questions and principled statistical answers. _Statistics in Medicine, 39_, 4922-4948. https://doi.org/10.1002/sim.8741), or to perform a simulation study yourself.

Finally, it is important to always keep in mind that all the techniques discussed here were developed under the assumption of no unobserved confounding. This means that all relevant confounders should be included as covariates. We will discuss some scenarios of unobserved confounding that we can account for with particular techniques in the coming weeks. Furthermore, sensitivity analysis is a valuable approach to investigate how the effect of unobserved confounding can be further investigated (not covered in this course; for more information see for instance: Blackwell, M. (2013). A selection bias approach to sensitivity analysis for causal effects. _Political Analysis, 22_, 169-182. https://doi.org/10.1093/pan/mpt006).  

---
